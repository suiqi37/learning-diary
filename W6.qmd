---
title: "Classification"
editor: visual
---

## Summary

### Review of how classified data is used

Different sensors used for different mapping purposes, but can be mixed and matched (used intechangably).

![Different techniques to characterize UGSs](img/6.1.png)

Source:[Shahtahmassebi et al. 2021](https://www.sciencedirect.com/science/article/pii/S1618866720307639?casa_token=ZrACATZktIAAAAAA:9bCBg0pBWBsIPmYMufywYK54cyPXoImsgNxQCN_JBR2zUQ50mvnKHcKZ9CnB2ywCNNsOCw-tpBU#!)

-   Classification and regression trees (CART)

classification trees:

Gini impurity= 1-(probability of yes)\^2-(the probability of no)\^2

regression trees:

Move to each point on the x axis \> calculate the average \> use this average as a new threshold and get the SSR. \>Use the threshold that gives smallest SSR.\> Repeat for the remaining sections.

Solve Overfitting:

1.  limit how trees grow (e.g. a minimum number of pixels in a leaf, 20 is often used)

2.  Weakest link pruning (with tree score)

\*The second method is more complicated, usually the first method is sufficient

-   Random Forests

For each tree about 70% of the training data is used in the bootstrap, 30% is left out of the bag (OOB).\> Test the OOB data in the forest where all the trees didn't use it.\> Most votes wins!Repeat for all OOB samples

\*Multiple is better than one, so usually research uses RF instead of CART

### How to classify remotely sensed data

apply this to imagery(Image classification)

-   Unsupervised(clustering/k-means)

![DBSCAN](img/6.2.png)

Source:[Yuting Wan](https://www.researchgate.net/figure/Encoding-strategy-for-the-EAs-based-remote-sensing-image-clustering-approaches_fig2_320378302)

\*DBSCAN can handle complex data, is able to identify clusters with irregular shapes, but need set suitable parameters and can't handle where different classes can have similar spectral characteristics and can overlap.

![ISODATA](img/6.3.png)

Source:[Jensen 2016 p.409 / Muhammad Zulkarnain Abdul Rahman](https://people.utm.my/nurulhazrina/files/2015/05/L12-Unsupervised-classification.pdf)

\*ISODATA is capable of adjusting its parameters during the clustering process, and can handle a pixel contains a mixture of different land covers, but may have difficulty handling complex classes that have a mixture of different land covers.

-   Supervised

![Maximum likelihood](img/6.4.png)

Source:[Núñez et al. 2018 High-Resolution Satellite Imagery Classification for Urban Form Detection](https://www.intechopen.com/chapters/64971)

\*ML is often considered one of the most accurate classification algorithms for remote sensing data, especially when the data is normally distributed, can handle multiple classes in the data.But deviations from normality can lead to biased classification results, and it's sensitive to training data and time-consuming.

![Support Vector Machine (SVM)](img/6.5.png)

Source:[skilltohire](https://medium.com/@skilltohire/support-vector-machines-4d28a427ebd)

![Support Vector Machine (SVM)](img/6.6.png)

Source:[Soner Yildirim](https://towardsdatascience.com/hyperparameter-tuning-for-support-vector-machines-c-and-gamma-parameters-6a5097416167)

\*SVM doesn't need parametric, making it suitable for remote sensing data that may not be normally distributed. And it can handle high-dimensional remote sensing data with many features. But it lack interpretability, making it difficult to understand why certain classification decisions were made.

## Applications

-   SVM 

In [@Pal2006], two experiments were conducted to compare the performance of multi-class support vector machines (SVMs) against maximum likelihood (ML) and artificial neural network (ANN) methods in terms of classification accuracy. The experiments focused on land cover classification using multispectral (Landsat-7 ETM+) and hyperspectral (DAIS) data in test areas located in eastern England and central Spain. The findings demonstrate that the SVM classifier achieved higher classification accuracy compared to the ML and ANN classifiers. Furthermore, the results suggest that the SVM classifier is suitable for use with small training datasets and high-dimensional data.

In this article, one against one of SVM performs better than one against the rest, The higher training time requirements of the 'one against one' approach may be due the algorithm used to solve quadratic programming optimization problem.The results indicate that SVM can achieve high classification accuracy with high dimensional data, even if the size of the training dataset is small.

It is recommended to use one against one to generate multi-class SVM. But is ""one against one performing better than one against the rest" always been like this, or is it influenced by the research object chosen in the article?

-   Unsupervised and supervised in remote sensing classification 

In a classification study of LULC in Nepal, supervised classification methods (using MLC) yielded higher accuracy than unsupervised methods (using ISODATA)[@KBK].

Why is there a big difference in the accuracy of different band combinations? Possibly affected by shadowing effects, which are significantly reduced in ratioband combinations

## Reflection

Compared with Unsupervised classification, supervised classification has higher accuracy, among which MLC is the mainstream method, and it has higher accuracy and interpretability.

Different classification methods can distinguish different objects, and existing methods have made full use of the bands that existing sensors can detect. The main direction of current research is how to improve the accuracy of classification and which bands to filter to get the desired research object
